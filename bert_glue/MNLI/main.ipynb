{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-13T13:54:57.395245Z",
     "start_time": "2024-05-13T13:54:34.842873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 392702\n    })\n    validation_matched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 9815\n    })\n    validation_mismatched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 9832\n    })\n    test_matched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 9796\n    })\n    test_mismatched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 9847\n    })\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"glue\", \"mnli\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3666d3aba3efacd6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:54:57.783556Z",
     "start_time": "2024-05-13T13:54:57.396250Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8f41c3b7e82f25",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:54:57.787492Z",
     "start_time": "2024-05-13T13:54:57.784565Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_fun(examples):\n",
    "    return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c905e6ad40b7a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:54:58.207343Z",
     "start_time": "2024-05-13T13:54:57.788496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/9832 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73c7b15871dd45faa1127bf22c6f699e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 392702\n    })\n    validation_matched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9815\n    })\n    validation_mismatched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9832\n    })\n    test_matched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9796\n    })\n    test_mismatched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9847\n    })\n})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_datasets = data.map(tokenize_fun, batched=True)\n",
    "tokenizer_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5676f48c1f7780d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:54:58.213210Z",
     "start_time": "2024-05-13T13:54:58.208350Z"
    }
   },
   "outputs": [],
   "source": [
    "#对数据集进行填充操作\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4835ab13f7a0101",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:54:58.216812Z",
     "start_time": "2024-05-13T13:54:58.214214Z"
    }
   },
   "outputs": [],
   "source": [
    "#训练参数\n",
    "from transformers import TrainingArguments\n",
    "# \n",
    "# training_args = TrainingArguments(\"out_files\",\n",
    "#                                   per_device_train_batch_size=16,\n",
    "#                                   num_train_epochs=1,\n",
    "#                                   logging_steps=50,\n",
    "#                                   evaluation_strategy='steps')\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:54:58.219552Z",
     "start_time": "2024-05-13T13:54:58.217816Z"
    }
   },
   "id": "6fd0617e396bdfdd",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28be2a523ac30f36",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:54:58.223338Z",
     "start_time": "2024-05-13T13:54:58.220557Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bf5e700b6c6e516",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:54:58.226138Z",
     "start_time": "2024-05-13T13:54:58.223338Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# from datasets import load_metric\n",
    "# \n",
    "# metric = load_metric(\"glue\", \"mnli\")\n",
    "# \n",
    "# \n",
    "# def compute_metrics(eval_preds):\n",
    "#     predictions, labels = eval_preds\n",
    "#     predictions = np.argmax(predictions, axis=1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\admin\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\accuracy\\9756d5fa4a0f9da966341741fc3926eafdc604b8276add51d5abbaa8958a25f9 (last modified on Mon May 13 15:29:26 2024) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='201' max='24544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  201/24544 02:34 < 5:15:35, 1.29 it/s, Epoch 0.01/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>1.108900</td>\n      <td>1.036048</td>\n      <td>0.460927</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.016300</td>\n      <td>0.970233</td>\n      <td>0.536220</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.881700</td>\n      <td>0.866380</td>\n      <td>0.612736</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='195' max='1227' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 195/1227 00:03 < 00:19, 53.57 it/s]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 27\u001B[0m\n\u001B[0;32m     16\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForSequenceClassification\u001B[38;5;241m.\u001B[39mfrom_pretrained(checkpoint, num_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m     18\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     19\u001B[0m     model,\n\u001B[0;32m     20\u001B[0m     training_args,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics,\n\u001B[0;32m     26\u001B[0m )\n\u001B[1;32m---> 27\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1624\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1622\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1623\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1624\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[0;32m   1625\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   1626\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[0;32m   1627\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[0;32m   1628\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[0;32m   1629\u001B[0m     )\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2029\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2026\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m=\u001B[39m epoch \u001B[38;5;241m+\u001B[39m (step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m steps_skipped) \u001B[38;5;241m/\u001B[39m steps_in_epoch\n\u001B[0;32m   2027\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m-> 2029\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n\u001B[0;32m   2030\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2031\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_substep_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2412\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2410\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   2411\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_evaluate:\n\u001B[1;32m-> 2412\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(ignore_keys\u001B[38;5;241m=\u001B[39mignore_keys_for_eval)\n\u001B[0;32m   2413\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step, metrics)\n\u001B[0;32m   2415\u001B[0m     \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3229\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3226\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   3228\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[1;32m-> 3229\u001B[0m output \u001B[38;5;241m=\u001B[39m eval_loop(\n\u001B[0;32m   3230\u001B[0m     eval_dataloader,\n\u001B[0;32m   3231\u001B[0m     description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3232\u001B[0m     \u001B[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;00m\n\u001B[0;32m   3233\u001B[0m     \u001B[38;5;66;03m# self.args.prediction_loss_only\u001B[39;00m\n\u001B[0;32m   3234\u001B[0m     prediction_loss_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   3235\u001B[0m     ignore_keys\u001B[38;5;241m=\u001B[39mignore_keys,\n\u001B[0;32m   3236\u001B[0m     metric_key_prefix\u001B[38;5;241m=\u001B[39mmetric_key_prefix,\n\u001B[0;32m   3237\u001B[0m )\n\u001B[0;32m   3239\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[0;32m   3240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3440\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3434\u001B[0m     inputs_host \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   3435\u001B[0m         inputs_decode\n\u001B[0;32m   3436\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m inputs_host \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   3437\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m nested_concat(inputs_host, inputs_decode, padding_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[0;32m   3438\u001B[0m     )\n\u001B[0;32m   3439\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m logits \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 3440\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mpad_across_processes(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, pad_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[0;32m   3441\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_logits_for_metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3442\u001B[0m         logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:2350\u001B[0m, in \u001B[0;36mAccelerator.pad_across_processes\u001B[1;34m(self, tensor, dim, pad_index, pad_first)\u001B[0m\n\u001B[0;32m   2317\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpad_across_processes\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensor, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, pad_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, pad_first\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m   2318\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2319\u001B[0m \u001B[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001B[39;00m\n\u001B[0;32m   2320\u001B[0m \u001B[38;5;124;03m    they can safely be gathered.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2348\u001B[0m \u001B[38;5;124;03m    ```\u001B[39;00m\n\u001B[0;32m   2349\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2350\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pad_across_processes(tensor, dim\u001B[38;5;241m=\u001B[39mdim, pad_index\u001B[38;5;241m=\u001B[39mpad_index, pad_first\u001B[38;5;241m=\u001B[39mpad_first)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:417\u001B[0m, in \u001B[0;36mchained_operation.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(function)\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    416\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 417\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m DistributedOperationException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    419\u001B[0m         operation \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunction\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__module__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunction\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:684\u001B[0m, in \u001B[0;36mpad_across_processes\u001B[1;34m(tensor, dim, pad_index, pad_first)\u001B[0m\n\u001B[0;32m    681\u001B[0m     new_tensor[indices] \u001B[38;5;241m=\u001B[39m tensor\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m new_tensor\n\u001B[1;32m--> 684\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m recursively_apply(\n\u001B[0;32m    685\u001B[0m     _pad_across_processes, tensor, error_on_other_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, dim\u001B[38;5;241m=\u001B[39mdim, pad_index\u001B[38;5;241m=\u001B[39mpad_index, pad_first\u001B[38;5;241m=\u001B[39mpad_first\n\u001B[0;32m    686\u001B[0m )\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:126\u001B[0m, in \u001B[0;36mrecursively_apply\u001B[1;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(data)(\n\u001B[0;32m    118\u001B[0m         {\n\u001B[0;32m    119\u001B[0m             k: recursively_apply(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    123\u001B[0m         }\n\u001B[0;32m    124\u001B[0m     )\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m test_type(data):\n\u001B[1;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(data, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m error_on_other_type:\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    129\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsupported types (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) passed to `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`. Only nested list/tuple/dicts of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    130\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjects that are valid for `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_type\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` should be passed.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    131\u001B[0m     )\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:664\u001B[0m, in \u001B[0;36mpad_across_processes.<locals>._pad_across_processes\u001B[1;34m(tensor, dim, pad_index, pad_first)\u001B[0m\n\u001B[0;32m    661\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tensor\n\u001B[0;32m    663\u001B[0m \u001B[38;5;66;03m# Gather all sizes\u001B[39;00m\n\u001B[1;32m--> 664\u001B[0m size \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(tensor\u001B[38;5;241m.\u001B[39mshape, device\u001B[38;5;241m=\u001B[39mtensor\u001B[38;5;241m.\u001B[39mdevice)[\u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[0;32m    665\u001B[0m sizes \u001B[38;5;241m=\u001B[39m gather(size)\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[0;32m    666\u001B[0m \u001B[38;5;66;03m# Then pad to the maximum size\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "training_args = TrainingArguments(\"out_files\",\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=1,\n",
    "                                  logging_steps=50,\n",
    "                                  evaluation_strategy='steps')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenizer_datasets[\"train\"],\n",
    "    eval_dataset=tokenizer_datasets[\"validation_matched\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:57:49.189406Z",
     "start_time": "2024-05-13T13:54:58.227142Z"
    }
   },
   "id": "b2a4909b67b2d646",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfecce86630fb3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-13T13:57:49.190491Z"
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import Trainer\n",
    "# \n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenizer_datasets[\"train\"],  #取前20000个样本\n",
    "#     eval_dataset=tokenizer_datasets[\"validation_matched\"],\n",
    "#     data_collator=data_collator,\n",
    "#     tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )\n",
    "# \n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-13T13:57:49.190491Z"
    }
   },
   "id": "c6c066cd1768cf6e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2535bfe21d65650",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-13T13:57:49.191520Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenizer_datasets[\"validation_matched\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f11b875d8c0575",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-13T13:57:49.191520Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = load_metric(\"glue\", \"mnli\")\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c38857a627fe67",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-13T13:57:49.192481Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-13T13:57:49.192481Z"
    }
   },
   "id": "35bac420f0f9332f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
