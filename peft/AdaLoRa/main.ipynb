{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:09:37.540745Z",
     "start_time": "2024-05-16T02:09:20.976124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1725\n    })\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\",download_mode=\"reuse_dataset_if_exists\")\n",
    "raw_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/463 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50f77e1124484730b9d4fdf97f783087"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bc036c43f2d477d8d4112dbce525f25"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1cc6edf4dfe447c4b9a163bdcc3a8746"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:41:11.046768Z",
     "start_time": "2024-05-16T02:41:05.225046Z"
    }
   },
   "id": "a6291de1790406a4",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:41:14.463550Z",
     "start_time": "2024-05-16T02:41:14.459869Z"
    }
   },
   "id": "8dd5d2861102fd1f",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c16c72adf894c88a3b14177c1bde539"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/408 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "614a502c1df04f7c8e0d6de65d3e8491"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad1a68cbaa414dc5bd044e2d48a65b57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n        num_rows: 1725\n    })\n})"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:41:19.091618Z",
     "start_time": "2024-05-16T02:41:18.663605Z"
    }
   },
   "id": "e774e106bd413c68",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:41:40.525738Z",
     "start_time": "2024-05-16T02:41:40.522234Z"
    }
   },
   "id": "284dc0cdcad9ee96",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"out_files\",\n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=50,\n",
    "                                  evaluation_strategy='epoch')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:41:43.653670Z",
     "start_time": "2024-05-16T02:41:43.599063Z"
    }
   },
   "id": "a6f306556cbee442",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\admin\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\accuracy\\9756d5fa4a0f9da966341741fc3926eafdc604b8276add51d5abbaa8958a25f9 (last modified on Mon May 13 15:29:26 2024) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:41:50.659869Z",
     "start_time": "2024-05-16T02:41:46.326534Z"
    }
   },
   "id": "2dd03677493782f8",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at t5-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "T5ForSequenceClassification(\n  (transformer): T5Model(\n    (shared): Embedding(32128, 768)\n    (encoder): T5Stack(\n      (embed_tokens): Embedding(32128, 768)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n                (relative_attention_bias): Embedding(32, 12)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=768, out_features=3072, bias=False)\n                (wo): Linear(in_features=3072, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-11): 11 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=768, out_features=3072, bias=False)\n                (wo): Linear(in_features=3072, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (decoder): T5Stack(\n      (embed_tokens): Embedding(32128, 768)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n                (relative_attention_bias): Embedding(32, 12)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=768, out_features=3072, bias=False)\n                (wo): Linear(in_features=3072, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-11): 11 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=768, out_features=3072, bias=False)\n                (wo): Linear(in_features=3072, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (classification_head): T5ClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.0, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:53:53.783801Z",
     "start_time": "2024-05-16T02:53:52.264588Z"
    }
   },
   "id": "ce6c7ed9beecb8a0",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "PeftModelForSequenceClassification(\n  (base_model): AdaLoraModel(\n    (model): PeftModelForSequenceClassification(\n      (base_model): AdaLoraModel(\n        (model): AdaLoraModel(\n          (model): PeftModelForSequenceClassification(\n            (base_model): LoraModel(\n              (model): T5ForSequenceClassification(\n                (transformer): T5Model(\n                  (shared): Embedding(32128, 768)\n                  (encoder): T5Stack(\n                    (embed_tokens): Embedding(32128, 768)\n                    (block): ModuleList(\n                      (0): T5Block(\n                        (layer): ModuleList(\n                          (0): T5LayerSelfAttention(\n                            (SelfAttention): T5Attention(\n                              (q): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (k): Linear(in_features=768, out_features=768, bias=False)\n                              (v): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (o): Linear(in_features=768, out_features=768, bias=False)\n                              (relative_attention_bias): Embedding(32, 12)\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                          (1): T5LayerFF(\n                            (DenseReluDense): T5DenseActDense(\n                              (wi): Linear(in_features=768, out_features=3072, bias=False)\n                              (wo): Linear(in_features=3072, out_features=768, bias=False)\n                              (dropout): Dropout(p=0.1, inplace=False)\n                              (act): ReLU()\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                        )\n                      )\n                      (1-11): 11 x T5Block(\n                        (layer): ModuleList(\n                          (0): T5LayerSelfAttention(\n                            (SelfAttention): T5Attention(\n                              (q): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (k): Linear(in_features=768, out_features=768, bias=False)\n                              (v): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (o): Linear(in_features=768, out_features=768, bias=False)\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                          (1): T5LayerFF(\n                            (DenseReluDense): T5DenseActDense(\n                              (wi): Linear(in_features=768, out_features=3072, bias=False)\n                              (wo): Linear(in_features=3072, out_features=768, bias=False)\n                              (dropout): Dropout(p=0.1, inplace=False)\n                              (act): ReLU()\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                        )\n                      )\n                    )\n                    (final_layer_norm): T5LayerNorm()\n                    (dropout): Dropout(p=0.1, inplace=False)\n                  )\n                  (decoder): T5Stack(\n                    (embed_tokens): Embedding(32128, 768)\n                    (block): ModuleList(\n                      (0): T5Block(\n                        (layer): ModuleList(\n                          (0): T5LayerSelfAttention(\n                            (SelfAttention): T5Attention(\n                              (q): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (k): Linear(in_features=768, out_features=768, bias=False)\n                              (v): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (o): Linear(in_features=768, out_features=768, bias=False)\n                              (relative_attention_bias): Embedding(32, 12)\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                          (1): T5LayerCrossAttention(\n                            (EncDecAttention): T5Attention(\n                              (q): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (k): Linear(in_features=768, out_features=768, bias=False)\n                              (v): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (o): Linear(in_features=768, out_features=768, bias=False)\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                          (2): T5LayerFF(\n                            (DenseReluDense): T5DenseActDense(\n                              (wi): Linear(in_features=768, out_features=3072, bias=False)\n                              (wo): Linear(in_features=3072, out_features=768, bias=False)\n                              (dropout): Dropout(p=0.1, inplace=False)\n                              (act): ReLU()\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                        )\n                      )\n                      (1-11): 11 x T5Block(\n                        (layer): ModuleList(\n                          (0): T5LayerSelfAttention(\n                            (SelfAttention): T5Attention(\n                              (q): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (k): Linear(in_features=768, out_features=768, bias=False)\n                              (v): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (o): Linear(in_features=768, out_features=768, bias=False)\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                          (1): T5LayerCrossAttention(\n                            (EncDecAttention): T5Attention(\n                              (q): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (k): Linear(in_features=768, out_features=768, bias=False)\n                              (v): adalora.SVDLinear(\n                                (base_layer): lora.Linear(\n                                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                                  (lora_dropout): ModuleDict(\n                                    (default): Dropout(p=0.1, inplace=False)\n                                  )\n                                  (lora_A): ModuleDict(\n                                    (default): Linear(in_features=768, out_features=8, bias=False)\n                                  )\n                                  (lora_B): ModuleDict(\n                                    (default): Linear(in_features=8, out_features=768, bias=False)\n                                  )\n                                  (lora_embedding_A): ParameterDict()\n                                  (lora_embedding_B): ParameterDict()\n                                )\n                                (lora_dropout): ModuleDict(\n                                  (default): Dropout(p=0.01, inplace=False)\n                                )\n                                (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x768 (cuda:0)])\n                                (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x12 (cuda:0)])\n                                (lora_embedding_A): ParameterDict()\n                                (lora_embedding_B): ParameterDict()\n                                (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n                                (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n                              )\n                              (o): Linear(in_features=768, out_features=768, bias=False)\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                          (2): T5LayerFF(\n                            (DenseReluDense): T5DenseActDense(\n                              (wi): Linear(in_features=768, out_features=3072, bias=False)\n                              (wo): Linear(in_features=3072, out_features=768, bias=False)\n                              (dropout): Dropout(p=0.1, inplace=False)\n                              (act): ReLU()\n                            )\n                            (layer_norm): T5LayerNorm()\n                            (dropout): Dropout(p=0.1, inplace=False)\n                          )\n                        )\n                      )\n                    )\n                    (final_layer_norm): T5LayerNorm()\n                    (dropout): Dropout(p=0.1, inplace=False)\n                  )\n                )\n                (classification_head): T5ClassificationHead(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.0, inplace=False)\n                  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n                )\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AdaLoraConfig,TaskType,get_peft_model\n",
    "config = AdaLoraConfig(\n",
    "peft_type=\"ADALORA\", task_type=TaskType.SEQ_CLS, r=8, lora_alpha=32, target_modules=[\"q\",\"v\"],\n",
    "lora_dropout=0.01,\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T03:02:52.548438Z",
     "start_time": "2024-05-16T03:02:52.158475Z"
    }
   },
   "id": "1c259f740acad062",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 224,380,418 || trainable%: 0.3943017879572717\n"
     ]
    }
   ],
   "source": [
    "# from peft import LoraConfig, TaskType\n",
    "# from peft import get_peft_model\n",
    "# \n",
    "# peft_config = LoraConfig(task_type=TaskType.SEQ_CLS, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:55:58.560069Z",
     "start_time": "2024-05-16T02:55:52.196060Z"
    }
   },
   "id": "498fcad7c017974e",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T03:01:39.543209Z",
     "start_time": "2024-05-16T03:01:39.415275Z"
    }
   },
   "id": "b45712906245859e",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[61], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1624\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1622\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1623\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1624\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[0;32m   1625\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   1626\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[0;32m   1627\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[0;32m   1628\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[0;32m   1629\u001B[0m     )\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1928\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   1925\u001B[0m     rng_to_sync \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1927\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1928\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, inputs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(epoch_iterator):\n\u001B[0;32m   1929\u001B[0m     total_batched_samples \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1931\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39minclude_num_input_tokens_seen:\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\data_loader.py:452\u001B[0m, in \u001B[0;36mDataLoaderShard.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001B[39;00m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 452\u001B[0m     current_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(dataloader_iter)\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    454\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollate_fn(data)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\data\\data_collator.py:271\u001B[0m, in \u001B[0;36mDataCollatorWithPadding.__call__\u001B[1;34m(self, features)\u001B[0m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, features: List[Dict[\u001B[38;5;28mstr\u001B[39m, Any]]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[1;32m--> 271\u001B[0m     batch \u001B[38;5;241m=\u001B[39m pad_without_fast_tokenizer_warning(\n\u001B[0;32m    272\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer,\n\u001B[0;32m    273\u001B[0m         features,\n\u001B[0;32m    274\u001B[0m         padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding,\n\u001B[0;32m    275\u001B[0m         max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[0;32m    276\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_to_multiple_of,\n\u001B[0;32m    277\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_tensors,\n\u001B[0;32m    278\u001B[0m     )\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m batch:\n\u001B[0;32m    280\u001B[0m         batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\data\\data_collator.py:66\u001B[0m, in \u001B[0;36mpad_without_fast_tokenizer_warning\u001B[1;34m(tokenizer, *pad_args, **pad_kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39mdeprecation_warnings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsking-to-pad-a-fast-tokenizer\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 66\u001B[0m     padded \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;241m*\u001B[39mpad_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpad_kwargs)\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# Restore the state of the warning.\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     tokenizer\u001B[38;5;241m.\u001B[39mdeprecation_warnings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsking-to-pad-a-fast-tokenizer\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m warning_state\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3245\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.pad\u001B[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001B[0m\n\u001B[0;32m   3243\u001B[0m \u001B[38;5;66;03m# The model's main input name, usually `input_ids`, has be passed for padding\u001B[39;00m\n\u001B[0;32m   3244\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_input_names[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m encoded_inputs:\n\u001B[1;32m-> 3245\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3246\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou should supply an encoding or a list of encodings to this method \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3247\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthat includes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_input_names[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, but you provided \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(encoded_inputs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3248\u001B[0m     )\n\u001B[0;32m   3250\u001B[0m required_input \u001B[38;5;241m=\u001B[39m encoded_inputs[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_input_names[\u001B[38;5;241m0\u001B[39m]]\n\u001B[0;32m   3252\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m required_input \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(required_input, Sized) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(required_input) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m):\n",
      "\u001B[1;31mValueError\u001B[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T03:01:44.522573Z",
     "start_time": "2024-05-16T03:01:41.196435Z"
    }
   },
   "id": "5a500603e09702e7",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dcef3276170930c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
